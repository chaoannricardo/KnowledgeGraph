{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ef4959",
   "metadata": {},
   "source": [
    "# Sequence 2 Sequence\n",
    "#### Reference:\n",
    "* https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fb9422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "import codecs\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "# activate cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "TSV_PATH = \"C:\\\\Users\\\\User\\\\Desktop\\\\Ricardo\\\\KnowledgeGraph_materials\\\\data_kg\\\\sequence2sequence\\\\Sentence pairs in English-Mandarin Chinese - 2021-06-27.tsv\"\n",
    "MAX_LENGTH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a610a97",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "937ca747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beginning token and ending token of sentence\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {\n",
    "            0: \"SOS\",\n",
    "            1: \"EOS\"\n",
    "        }\n",
    "        self.n_words = 2 # only SOS & EOS at this moment\n",
    "    \n",
    "    def addSentence(self, sentence, language):\n",
    "        if language == \"EN\":\n",
    "            for word in sentence.split(' '):\n",
    "                self.addWord(word)\n",
    "        elif language == \"ZH\":\n",
    "            for word in sentence:\n",
    "                self.addWord(word)\n",
    "                \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428d8022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizationString(s):\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Read lines....\")\n",
    "    pairs = []\n",
    "    \n",
    "    # Read the files and split into lines\n",
    "    data = codecs.open(TSV_PATH, encoding=\"utf8\", errors=\"ignore\")\n",
    "    for lineIndex, line in enumerate(data.readlines()):\n",
    "        line_list = line.split(\"\\t\")\n",
    "        first_sequence = line_list[1]\n",
    "        second_sequece = line_list[3]\n",
    "        \n",
    "        # deal with format of mandarin and english sequence\n",
    "        second_sequece = second_sequece.replace(\"\\r\\n\", \"\")\n",
    "        \n",
    "        pairs.append([normalizationString(first_sequence), second_sequece])\n",
    "        \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c706913",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Since there are a lot of example sentences and we want to train something quickly,\n",
    "we’ll trim the data set to only relatively short and simple sentences. \n",
    "Here the maximum length is 10 words (that includes ending punctuation) \n",
    "and we’re filtering to sentences that translate to the form “I am” or “He is” etc.\n",
    "(accounting for apostrophes replaced earlier).\n",
    "'''\n",
    "\n",
    "eng_prefixed = (\n",
    "    \"i am\", \"i m\",\n",
    "    \"he is\", \"he s\",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re\",\n",
    "    \"we are\", \"we re\",\n",
    "    \"they are\", \"they re\"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeac0863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read lines....\n",
      "Read 56574 sentence pairs\n",
      "Counted words...\n",
      "ZH 51582\n",
      "EN 32\n",
      "['我在一條河的附近長大。', 'i grew up near a river .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    \n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0], \"EN\")\n",
    "        output_lang.addSentence(pair[1], \"ZH\")\n",
    "        \n",
    "    print(\"Counted words...\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData(\"EN\", \"ZH\", True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d97c20",
   "metadata": {},
   "source": [
    "# Model Stage\n",
    "#### Documetations\n",
    "* Pytorch Embedding: https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "* Pytorh GRU: https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "* Pytorch Softmax: https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html\n",
    "* Pytorch View: https://pytorch.org/docs/stable/generated/torch.Tensor.view.html\n",
    "* Pytorch Linear: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f6c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        self.hidden_size = hidden_size   \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        # 它能將一個含任意實數的K維向量 「壓縮」到另一個K維實向量中，\n",
    "        # 使得每一個元素的範圍都在(0,1)之間，並且所有元素的和為1\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_vector, hidden):\n",
    "        output = self.embedding(input_vector).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        # Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67cf58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_vector, hidden):\n",
    "        output = self.embedding(input_vector).View(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output_hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33347df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Decoder\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.ouput_size = output_size\n",
    "        self.dropout_p = droupout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # initiate model attributes\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input_vector, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input_vector).View(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        attn_weight = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        output = F.log_softmax(self.out(output[0], dim=1))\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexFromSentence(lang, sentence):\n",
    "    if lang == \"EN\":\n",
    "        return [lang.word2index[word] for word in sentence.split(\" \")]\n",
    "    elif lang == \"ZH\":\n",
    "        return [lang.word2index[word] for word in sentence]\n",
    "    \n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b3a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainging model\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tenosr, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "         criterion, max_length=MAX_LENGTH):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    \n",
    "    loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc9c1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa3639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
