{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9ba503-5bcf-49d0-9f4e-6f09e099242c",
   "metadata": {},
   "source": [
    "# Sequence 2 Sequence\n",
    "#### Reference:\n",
    "* https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa66df0b-e0b7-4395-a34d-27283bf25f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "import codecs\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# activate cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "TSV_PATH = \"C:\\\\Users\\\\User\\\\Desktop\\\\Ricardo\\\\KnowledgeGraph_materials\\\\data_kg\\\\sequence2sequence\\\\Sentence pairs in English-Mandarin Chinese - 2021-06-27.tsv\"\n",
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03157f68-3f1b-43ca-8c1e-d3c67dac2d4d",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4ebc91-6702-4f0c-b644-a9c68bb3eff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Let s try something .', '我們試試看！'], ['I have to go to sleep .', '我该去睡觉了。'], ['Today is June th and it is Muiriel s birthday !', '今天是６月１８号，也是Muiriel的生日！'], ['Muiriel is now .', 'Muiriel现在20岁了。'], ['The password is Muiriel .', '密码是\"Muiriel\"。'], ['I will be back soon .', '我很快就會回來。'], ['I m at a loss for words .', '我不知道應該說什麼才好。'], ['This is never going to end .', '這個永遠完不了了。'], ['This is never going to end .', '这将永远继续下去。'], ['I just don t know what to say .', '我只是不知道應該說什麼而已……']]\n"
     ]
    }
   ],
   "source": [
    "# parsing data\n",
    "\n",
    "file = codecs.open(TSV_PATH, mode=\"r\", errors=\"ignore\", encoding=\"utf8\")\n",
    "\n",
    "line_pairs = []\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "for line in file.readlines():\n",
    "    line_split_list = line.split(\"\\t\")\n",
    "    line_pairs.append([normalizeString(line_split_list[1].replace(\"\\r\\n\", \"\").replace(\"\\n\", \"\")),\n",
    "                       line_split_list[3].replace(\"\\r\\n\", \"\").replace(\"\\n\", \"\")])\n",
    "    \n",
    "    \n",
    "print(line_pairs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3852f8c7-9969-4e0c-a724-aa21e9eaae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name, LNG):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence, LNG):\n",
    "        if LNG == \"EN\":\n",
    "            for word in sentence.split(' '):\n",
    "                self.addWord(word)\n",
    "        elif LNG == \"ZH\":\n",
    "            for word in sentence:\n",
    "                self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d539962-bf24-4104-a3a0-d4770566251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, line_pairs, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[line_element for line_element in l] for l in line_pairs]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2, \"ZH\")\n",
    "        output_lang = Lang(lang1, \"EN\")\n",
    "    else:\n",
    "        input_lang = Lang(lang1, \"EN\")\n",
    "        output_lang = Lang(lang2, \"ZH\")\n",
    "        \n",
    "    print(pairs[0:10])\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465f193c-63e0-4c8a-af74-b7752b47c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1af53c-3ffd-4ad5-97dd-41aa7aa49524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "[['Let s try something .', '我們試試看！'], ['I have to go to sleep .', '我该去睡觉了。'], ['Today is June th and it is Muiriel s birthday !', '今天是６月１８号，也是Muiriel的生日！'], ['Muiriel is now .', 'Muiriel现在20岁了。'], ['The password is Muiriel .', '密码是\"Muiriel\"。'], ['I will be back soon .', '我很快就會回來。'], ['I m at a loss for words .', '我不知道應該說什麼才好。'], ['This is never going to end .', '這個永遠完不了了。'], ['This is never going to end .', '这将永远继续下去。'], ['I just don t know what to say .', '我只是不知道應該說什麼而已……']]\n",
      "Read 56574 sentence pairs\n",
      "Trimmed to 56571 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "EN 14702\n",
      "ZH 4547\n",
      "['I wish Tom could have been there .', '我希望汤姆能在那里。']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, line_pairs, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0], \"EN\")\n",
    "        output_lang.addSentence(pair[1], \"ZH\")\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('EN', 'ZH', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340f85b-a11a-47bf-aca1-dcfb118c67ed",
   "metadata": {},
   "source": [
    "# Model Stage\n",
    "#### Documetations\n",
    "* Pytorch Embedding: https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "* Pytorh GRU: https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "* Pytorch Softmax: https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html\n",
    "* Pytorch View: https://pytorch.org/docs/stable/generated/torch.Tensor.view.html\n",
    "* Pytorch Linear: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b42a5d4e-dafc-4ad9-a8f6-3f09997d41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187dcc58-7bff-4d95-b5da-0d80e3c3a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc9567ee-fe93-465e-adbf-385c3e91e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence, LNG):\n",
    "    if LNG == \"EN\":\n",
    "        return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "    elif LNG == \"ZH\":\n",
    "        return [lang.word2index[word] for word in sentence]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence, LNG):\n",
    "    indexes = indexesFromSentence(lang, sentence, LNG)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair, LNG_pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0], LNG_pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1], LNG_pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45d484fc-5568-4b77-9c43-4a4dade86cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60aa3ab6-e21c-45d4-a157-d2ac7a90b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11d922df-bffc-4bc1-96a3-c77eaa246f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, LNG_pair, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs), LNG_pair)\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85fc3266-5c0e-44b1-a831-7f0b658d7905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95c91a7f-ac81-43e5-8fa1-07f8cb8db2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 10s (- 1365m 4s) (10 0%) 6.8984\n",
      "0m 11s (- 696m 10s) (20 0%) 5.5454\n",
      "0m 11s (- 471m 48s) (30 0%) 4.1598\n",
      "0m 11s (- 358m 44s) (40 0%) 3.1285\n",
      "0m 11s (- 290m 25s) (50 0%) 4.2476\n",
      "0m 11s (- 246m 32s) (60 0%) 5.1989\n",
      "0m 12s (- 214m 22s) (70 0%) 4.9957\n",
      "0m 12s (- 190m 57s) (80 0%) 5.5468\n",
      "0m 12s (- 172m 6s) (90 0%) 3.4261\n",
      "0m 12s (- 158m 11s) (100 0%) 5.0742\n",
      "0m 12s (- 146m 7s) (110 0%) 5.1236\n",
      "0m 13s (- 136m 10s) (120 0%) 5.6310\n",
      "0m 13s (- 127m 19s) (130 0%) 4.6876\n",
      "0m 13s (- 119m 53s) (140 0%) 4.4907\n",
      "0m 13s (- 113m 42s) (150 0%) 5.0028\n",
      "0m 13s (- 108m 24s) (160 0%) 5.8606\n",
      "0m 14s (- 103m 37s) (170 0%) 5.7695\n",
      "0m 14s (- 99m 22s) (180 0%) 4.7383\n",
      "0m 14s (- 95m 46s) (190 0%) 5.0802\n",
      "0m 14s (- 92m 15s) (200 0%) 4.7845\n",
      "0m 14s (- 88m 56s) (210 0%) 4.9712\n",
      "0m 15s (- 86m 12s) (220 0%) 5.2657\n",
      "0m 15s (- 83m 37s) (230 0%) 4.5487\n",
      "0m 15s (- 81m 21s) (240 0%) 5.2569\n",
      "0m 15s (- 79m 1s) (250 0%) 4.9823\n",
      "0m 16s (- 77m 1s) (260 0%) 5.3104\n",
      "0m 16s (- 75m 10s) (270 0%) 5.4942\n",
      "0m 16s (- 73m 24s) (280 0%) 4.9843\n",
      "0m 16s (- 71m 49s) (290 0%) 5.4122\n",
      "0m 16s (- 70m 13s) (300 0%) 5.2378\n",
      "0m 17s (- 69m 1s) (310 0%) 5.5014\n",
      "0m 17s (- 67m 39s) (320 0%) 4.2481\n",
      "0m 17s (- 67m 10s) (330 0%) 6.5710\n",
      "0m 18s (- 66m 2s) (340 0%) 5.3646\n",
      "0m 18s (- 65m 15s) (350 0%) 6.3407\n",
      "0m 18s (- 64m 2s) (360 0%) 4.6359\n",
      "0m 18s (- 63m 8s) (370 0%) 5.4818\n",
      "0m 18s (- 62m 4s) (380 0%) 4.6333\n",
      "0m 19s (- 61m 4s) (390 0%) 3.6717\n",
      "0m 19s (- 60m 16s) (400 0%) 5.4617\n",
      "0m 19s (- 59m 21s) (410 0%) 3.7785\n",
      "0m 19s (- 58m 27s) (420 0%) 4.0251\n",
      "0m 20s (- 57m 59s) (430 0%) 6.0389\n",
      "0m 20s (- 57m 18s) (440 0%) 5.3844\n",
      "0m 20s (- 56m 48s) (450 0%) 4.0201\n",
      "0m 20s (- 56m 12s) (460 0%) 5.2158\n",
      "0m 20s (- 55m 27s) (470 0%) 3.9112\n",
      "0m 21s (- 54m 48s) (480 0%) 4.3446\n",
      "0m 21s (- 54m 12s) (490 0%) 3.9000\n",
      "0m 21s (- 53m 37s) (500 0%) 4.2939\n",
      "0m 21s (- 53m 10s) (510 0%) 4.8491\n",
      "0m 22s (- 52m 43s) (520 0%) 5.1098\n",
      "0m 22s (- 52m 22s) (530 0%) 5.7351\n",
      "0m 22s (- 51m 48s) (540 0%) 4.8091\n",
      "0m 22s (- 51m 21s) (550 0%) 5.2548\n",
      "0m 22s (- 50m 49s) (560 0%) 4.7181\n",
      "0m 23s (- 50m 23s) (570 0%) 4.6900\n",
      "0m 23s (- 50m 2s) (580 0%) 5.3427\n",
      "0m 23s (- 49m 38s) (590 0%) 4.6586\n",
      "0m 23s (- 49m 12s) (600 0%) 4.2487\n",
      "0m 23s (- 48m 44s) (610 0%) 4.0270\n",
      "0m 24s (- 48m 19s) (620 0%) 4.3582\n",
      "0m 24s (- 47m 57s) (630 0%) 4.6073\n",
      "0m 24s (- 47m 39s) (640 0%) 5.3433\n",
      "0m 24s (- 47m 14s) (650 0%) 4.4625\n",
      "0m 25s (- 46m 57s) (660 0%) 4.5457\n",
      "0m 25s (- 46m 34s) (670 0%) 4.1294\n",
      "0m 25s (- 46m 20s) (680 0%) 5.5338\n",
      "0m 25s (- 45m 59s) (690 0%) 4.6224\n",
      "0m 25s (- 45m 44s) (700 0%) 4.2888\n",
      "0m 26s (- 45m 33s) (710 0%) 4.7379\n",
      "0m 26s (- 45m 16s) (720 0%) 5.1083\n",
      "0m 26s (- 45m 2s) (730 0%) 4.2206\n",
      "0m 26s (- 44m 44s) (740 0%) 3.9182\n",
      "0m 27s (- 44m 35s) (750 1%) 4.9997\n",
      "0m 27s (- 44m 26s) (760 1%) 5.3815\n",
      "0m 27s (- 44m 17s) (770 1%) 5.6402\n",
      "0m 27s (- 44m 6s) (780 1%) 6.0652\n",
      "0m 28s (- 43m 56s) (790 1%) 5.2290\n",
      "0m 28s (- 43m 40s) (800 1%) 4.8368\n",
      "0m 28s (- 43m 26s) (810 1%) 4.8286\n",
      "0m 28s (- 43m 12s) (820 1%) 4.3378\n",
      "0m 28s (- 43m 2s) (830 1%) 4.3844\n",
      "0m 29s (- 42m 55s) (840 1%) 5.1736\n",
      "0m 29s (- 42m 41s) (850 1%) 4.8401\n",
      "0m 29s (- 42m 30s) (860 1%) 4.3778\n",
      "0m 29s (- 42m 18s) (870 1%) 3.5842\n",
      "0m 30s (- 42m 19s) (880 1%) 5.0108\n",
      "0m 30s (- 42m 9s) (890 1%) 5.1353\n",
      "0m 30s (- 41m 56s) (900 1%) 4.9840\n",
      "0m 30s (- 41m 48s) (910 1%) 5.3726\n",
      "0m 31s (- 41m 38s) (920 1%) 5.0209\n",
      "0m 31s (- 41m 25s) (930 1%) 4.5936\n",
      "0m 31s (- 41m 12s) (940 1%) 4.2568\n",
      "0m 31s (- 41m 2s) (950 1%) 4.9216\n",
      "0m 31s (- 40m 53s) (960 1%) 5.1147\n",
      "0m 32s (- 40m 56s) (970 1%) 5.5264\n",
      "0m 32s (- 40m 52s) (980 1%) 5.0008\n",
      "0m 32s (- 40m 41s) (990 1%) 4.6836\n",
      "0m 32s (- 40m 34s) (1000 1%) 4.3620\n",
      "0m 33s (- 40m 24s) (1010 1%) 4.8605\n",
      "0m 33s (- 40m 17s) (1020 1%) 4.7870\n",
      "0m 33s (- 40m 13s) (1030 1%) 5.3008\n",
      "0m 33s (- 40m 7s) (1040 1%) 5.0787\n",
      "0m 34s (- 39m 59s) (1050 1%) 4.2102\n",
      "0m 34s (- 39m 50s) (1060 1%) 3.7864\n",
      "0m 34s (- 39m 42s) (1070 1%) 4.9356\n",
      "0m 34s (- 39m 34s) (1080 1%) 4.7521\n",
      "0m 34s (- 39m 26s) (1090 1%) 4.5605\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-725d8aa24e4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrainIters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m75000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"EN\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ZH\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-fd171a3bbb0c>\u001b[0m in \u001b[0;36mtrainIters\u001b[1;34m(encoder, decoder, n_iters, LNG_pair, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         loss = train(input_tensor, target_tensor, encoder,\n\u001b[1;32m---> 19\u001b[1;33m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-77785d753587>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, [\"EN\", \"ZH\"], print_every=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
