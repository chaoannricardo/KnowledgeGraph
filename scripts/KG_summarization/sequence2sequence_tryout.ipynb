{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a88b2208",
   "metadata": {},
   "source": [
    "# Sequence 2 Sequence\n",
    "#### Reference:\n",
    "* https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2281e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "import codecs\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "# activate cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "TSV_PATH = \"C:\\\\Users\\\\User\\\\Desktop\\\\Ricardo\\\\KnowledgeGraph_materials\\\\data_kg\\\\sequence2sequence\\\\Sentence pairs in English-Mandarin Chinese - 2021-06-27.tsv\"\n",
    "MAX_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a7d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beginning token and ending token of sentence\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {\n",
    "            0: \"SOS\",\n",
    "            1: \"EOS\"\n",
    "        }\n",
    "        self.n_words = 2 # only SOS & EOS at this moment\n",
    "    \n",
    "    def addSentence(self, sentence, language):\n",
    "        if language == \"EN\":\n",
    "            for word in sentence.split(' '):\n",
    "                self.addWord(word)\n",
    "        elif language == \"ZH\":\n",
    "            for word in sentence:\n",
    "                self.addWord(word)\n",
    "                \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a8772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizationString(s):\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Read lines....\")\n",
    "    pairs = []\n",
    "    \n",
    "    # Read the files and split into lines\n",
    "    data = codecs.open(TSV_PATH, encoding=\"utf8\", errors=\"ignore\")\n",
    "    for lineIndex, line in enumerate(data.readlines()):\n",
    "        line_list = line.split(\"\\t\")\n",
    "        first_sequence = line_list[1]\n",
    "        second_sequece = line_list[3]\n",
    "        \n",
    "        # deal with format of mandarin and english sequence\n",
    "        second_sequece = second_sequece.replace(\"\\r\\n\", \"\")\n",
    "        \n",
    "        pairs.append([normalizationString(first_sequence), second_sequece])\n",
    "        \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206667ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Since there are a lot of example sentences and we want to train something quickly,\n",
    "we’ll trim the data set to only relatively short and simple sentences. \n",
    "Here the maximum length is 10 words (that includes ending punctuation) \n",
    "and we’re filtering to sentences that translate to the form “I am” or “He is” etc.\n",
    "(accounting for apostrophes replaced earlier).\n",
    "'''\n",
    "\n",
    "eng_prefixed = (\n",
    "    \"i am\", \"i m\",\n",
    "    \"he is\", \"he s\",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re\",\n",
    "    \"we are\", \"we re\",\n",
    "    \"they are\", \"they re\"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c714ac80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read lines....\n",
      "Read 56574 sentence pairs\n",
      "Counted words...\n",
      "ZH 51582\n",
      "EN 32\n",
      "['我在一條河的附近長大。', 'i grew up near a river .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    \n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0], \"EN\")\n",
    "        output_lang.addSentence(pair[1], \"ZH\")\n",
    "        \n",
    "    print(\"Counted words...\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData(\"EN\", \"ZH\", True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6170ce96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6c24a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
