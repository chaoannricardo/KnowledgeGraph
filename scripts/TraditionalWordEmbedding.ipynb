{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rising-wisconsin",
   "metadata": {},
   "source": [
    "# Traditional Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "armed-converter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------+\n",
      "  Welcome to MONPA: Multi-Objective NER POS Annotator for Chinese\n",
      "+---------------------------------------------------------------------+\n",
      "已找到 model檔。Found model file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\Windows_Storage\\\\Storage\\\\Github\\\\KnowledgeGraph\\\\scripts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import packages\n",
    "from gensim.models import word2vec\n",
    "from monpa import utils\n",
    "from tqdm import tqdm\n",
    "import codecs\n",
    "import logging\n",
    "import monpa\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-sender",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "found-bubble",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 306.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Length:  207715  \n",
      "\n",
      " 管中流過，凝結下來之蒸\n",
      "\n",
      "氣附著管外殼上。蒸氣可在管外凝結成一層薄膜後，再排\n",
      "\n",
      "至儲存槽，或排出後做適當之處置。在接觸式冷凝器中，\n",
      "\n",
      "則噴灑冷的液體以冷凝廢氣中之揮發性成份。 \n",
      "\n",
      "5 -30 \n",
      "\n",
      "\f",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "textElement = \"\"\n",
    "\n",
    "for fileIndex, fileElement in enumerate(tqdm(os.listdir(\"../data/\"))):\n",
    "    file = codecs.open(\"../data/\" + fileElement, 'r', encoding='utf8', errors='ignore')\n",
    "    for textIndex, textLines in enumerate(file):\n",
    "        textElement += textLines\n",
    "        \n",
    "    \n",
    "print(\"Text Length: \", len(textElement), \" \\n\\n\", textElement[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "awful-street",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2310 \n",
      "\n",
      " ['行动', '表明', '表示', '要求', '规定', '觉得', '认为', '认真', '认识', '说明', '转动', '转变', '转贴', '达到', '迅速', '过去', '过来', '运用', '这点', '这种', '这麽', '进入', '进步', '进行', '适应', '适当', '适用', '逐渐', '通常', '造成', '遇到', '遭到', '避免', '那麽', '部分', '采取', '里面', '重大', '重新', '重要', '问题', '防止', '附近', '限制', '随著', '集中', '需要', '高兴', '是不是', '说说']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-caa2e0aa211a>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data_temp = pd.read_csv(\"./stopwords/\" + fileElement, encoding=\"utf8\", sep=\"@#$%&*\")\n"
     ]
    }
   ],
   "source": [
    "# import stopwords list\n",
    "\n",
    "stopword_list = []\n",
    "\n",
    "for fileIndex, fileElement in enumerate(os.listdir(\"./stopwords/\")):\n",
    "    if fileElement[-2:] != \"md\":\n",
    "        data_temp = pd.read_csv(\"./stopwords/\" + fileElement, encoding=\"utf8\", sep=\"@#$%&*\")\n",
    "        stopword_list += data_temp.iloc[:, 0].tolist()\n",
    "        \n",
    "stopword_list = list(dict.fromkeys(stopword_list))\n",
    "        \n",
    "print(len(stopword_list), \"\\n\\n\", stopword_list[-50:])     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-antenna",
   "metadata": {},
   "source": [
    "# Create User-Defined Dict by entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lasting-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pd.read_csv(\"../results/210330_result/210330_dataset_entity_result_MONPA.csv\", sep=\",\", encoding=\"utf8\")\n",
    "\n",
    "entity_list = data_dict.iloc[:, 0].tolist()\n",
    "\n",
    "# remove blank inside entity element\n",
    "for elementIndex, element in enumerate(entity_list):\n",
    "    entity_list[elementIndex] = entity_list[elementIndex].replace(\" \", \"\")\n",
    "    entity_list[elementIndex] = entity_list[elementIndex].replace(\"  \", \"\")\n",
    "    entity_list[elementIndex] = entity_list[elementIndex].replace(\"\\\"\", \"\")\n",
    "\n",
    "\n",
    "data_dict_output = pd.DataFrame({\n",
    "    \"0\": entity_list,\n",
    "    \"1\": [int(1000000000 * float(str(data_dict.iloc[i, -1])[:-1])) for i in range(len(entity_list))],\n",
    "    \"2\": [\"UserEntity\" for i in range(len(entity_list))],\n",
    "})\n",
    "\n",
    "data_dict_output.to_csv(\"./dicts/monpa_entity_dict.txt\", encoding=\"utf8\", sep=\" \", index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-football",
   "metadata": {},
   "source": [
    "# Segment data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "standing-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in entity dictionary\n",
    "\n",
    "monpa.load_userdict(\"./dicts/monpa_entity_dict.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "outer-airport",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1332/1332 [08:29<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['安森', '美', '半導體', '', 'O', 'N Se', 'm', 'icon', 'd', 'uctor', '', '', '', '天', '發', '表', '新', '', 'R', 'D', 'M', '系列', '矽', '光', '電', '倍', '增', '', ' ', '', 'Si', 'P', 'M', '', '陣列', '', '將', '光', '學', '雷', '達', '', 'Li', 'D', 'A', 'R', '', ' 感', '測', '器', '', '力', '擴展到其', '廣', '泛', '', '智慧感', '測', '方案', '陣容', '', 'A', 'rray', 'R', 'D', 'M', '', '', '', '12', 'A', '20', '', 'Q', 'F', 'N', '', '市場', '', '首款', '符合', '車規', '', 'Si', 'P', 'M', '產品', '', '', '滿足', '汽車', '產業', '', '', '', '領', '域', 'Li', 'D', 'A', 'R', '應用', '中', '不斷', '增', '長', '', '需求', ''], ['A', 'rray', 'R', 'D', 'M', '', '', '', '12', 'A', '20', '', 'Q', 'F', 'N', '', '單', '片', '', '', '12', 'Si', 'P', 'M', '', '素', '陣列', '', '基', '於', '安森', '美', '半導體', '領', '先', '市場', '', 'R', 'D', 'M', '製程', '', '', '實', '現', '對', '近', '紅', '外', '', 'NI', 'R', '', '光', '', '高', '靈敏', '度', '', '從', '', '', '90', '', '奈米', '', 'n', 'm', '', '處', '達到', '領', '先', '業界', '', '18', '', '', '', '', '光', '子', '偵', '測', '效', '率', ' ', '', 'P', 'D', 'E', '', '', 'Si', 'P', 'M', '', '高', '內', '部', '增', '益', '', '其靈敏度', '', '達到', '單', '光', '子', '水', '準', '', '該', '功能', '與', '高', 'P', 'D', 'E', '結合', '', '', '', '檢測', '', '微', '弱', '', '返回', '信號', '', '', '', '', '', '低', '反', '射', '目', '標', '', '', '', '偵', '測', '', '更', '遠', '', '距離', ''], ['', '外', '', '該', '產品', '符合', 'A', 'E', 'C', '', 'Q', '10', '', '', '國際', '汽車', '電子', '協', '會', '', '', '', ' ', 'I', 'A', 'T', 'F', '16', '', '49', '', '國際', '汽車', '推動', '', '組', '', '', '技術', '規', '範', '開發', '', 'Si', 'P', 'M', '技術', '近年', '來', '蓬勃', '發展', '', '', '於', '', '獨', '特', '', '功能', '組', '', '', '成', '為', '廣', '', '市場', '深度', '感', '測', '應用', '', '首選感', '測', '器', '', 'Si', 'P', 'M', '', '', '明', '亮', '', '陽', '光', '條件', '', '進行', '長', '距離', '測', '', '時', '提供', '最佳', '', '訊噪', '', '性能', '', '', '', '優勢', '包括', '較', '低', '', '電', '源', '偏', '置', '', '較', '低', '', '溫度', '變', '化', '敏感性', '', '', '', '成', '為', '', '傳統', '雪崩', '光', '電', '二', '極', '體', '', 'A', 'P', 'D', '', '', '系統', '', '理想', '升', '級', '產品', ''], ['Si', 'P', 'M', '採用', '大批量', 'C', 'M', 'O', 'S', '製程', '生產', '', '', '實', '現', '', '低', '', '偵', '測', '器', '成本', '', '從', '', '實', '現', '應用', '於', '廣', '', '市場', '', 'Li', 'D', 'A', 'R', '方案', '', ' ', '   ', '', '激', '光', '測', '量', '物', '體', '', '距離', '', '跨', '越', '', '汽車', '', '消費', '', '工業', '應用', '領', '域', '', '', '汽車領域', '', 'Li', 'D', 'A', 'R', '', '', '於', '提', '升', '安', '全', '性', '', '駕駛', '輔助', '系統', '', 'A', 'D', 'A', 'S', '', '', '通', '過', '與其', '', '感知', '模式', '互補', '', '提供', '冗餘', '', '輔助', '', '車', '道', '保', '持', '和交', '通', '擁堵', '輔助', '', '功能', '', 'Li', 'D', 'A', 'R', '正普', '遍', '', '於', '全', '自動', '駕駛', '', '', '案', '例', '', '例', '', '機器', '', '運', '輸', '', '', '安', '全', '', '實', '時', '導', '航', '環境', ''], ['受', '益', '於', 'A', 'rray', 'R', 'D', 'M', '', '', '', '12', 'A', '20', '', 'Q', 'F', 'N', '', '高', 'P', 'D', 'E', '', '支持', '這', '', '功能', '', 'Li', 'D', 'A', 'R', '系統', '', '', '證', '明', '', '', '30', '', '米', '', '', '距離', '測', '', '', '更', '遠', '', '距離', '', '車輛', '', '更多', '時', '間', '來', '應', '對', '意', '外', '障礙', '', ' ', '   安森', '美', '半導體', '汽車感', '測', '部門', '資', '深', '總監', 'Wa', 'd', 'e', 'A', 'ppel', 'm', '', '表', '示', '', ' ', 'Li', 'D', 'A', 'R', '提供', '', '高', '解', '析', '度', '深度', '數', '據', '', '', '充滿', '挑戰', '', '微', '光', '條件', '下即', '時', '準', '確', '', '識別', '物', '體', '']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# divide sentences and segment by monpa\n",
    "textList = utils.short_sentence(textElement)\n",
    "\n",
    "cutResultList = []\n",
    "\n",
    "for textIndex, textElement in enumerate(tqdm(textList)):\n",
    "    cutResult = monpa.cut(textElement)\n",
    "    for elementIndex, element in enumerate(cutResult):\n",
    "        if element in stopword_list:\n",
    "            cutResult[elementIndex] = \"\"\n",
    "    cutResultList.append(cutResult)\n",
    "\n",
    "print(cutResultList[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "angry-andrews",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1332/1332 [00:00<00:00, 16049.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# create data for word2vec training\n",
    "\n",
    "lineList = []\n",
    "\n",
    "for sentencesIndex, sentencesElementList in enumerate(tqdm(cutResultList)):\n",
    "    tokenElement = \"\"\n",
    "    for elementIndex, element in enumerate(sentencesElementList):\n",
    "        tokenElement += (element + \" \")\n",
    "    lineList.append(tokenElement)\n",
    "    \n",
    "data_output_word2vec = pd.DataFrame({\n",
    "    \"Token Sentence\":lineList\n",
    "})\n",
    "\n",
    "data_output_word2vec.to_csv(\"../results/210330_result/210330_token_sentences_for_word2vec.csv\", encoding=\"utf8\", sep=\" \", header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-payday",
   "metadata": {},
   "source": [
    "# Word2Vec Model Training\n",
    "* Reference: https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#sphx-glr-auto-examples-tutorials-run-word2vec-py\n",
    "* Reference: https://radimrehurek.com/gensim/auto_examples/tutorials/run_annoy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "turkish-occasions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------+\n",
      "  Welcome to MONPA: Multi-Objective NER POS Annotator for Chinese\n",
      "+---------------------------------------------------------------------+\n",
      "已找到 model檔。Found model file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\Windows_Storage\\\\Storage\\\\Github\\\\KnowledgeGraph\\\\scripts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import packages\n",
    "from gensim.models import word2vec\n",
    "from monpa import utils\n",
    "from tqdm import tqdm\n",
    "import codecs\n",
    "import logging\n",
    "import monpa\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "charming-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = word2vec.LineSentence(\"../results/210330_result/210330_token_sentences_for_word2vec.csv\")\n",
    "model = word2vec.Word2Vec(sentences, size=240)\n",
    "\n",
    "model.save(\"../models/210330_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exact-jungle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9057946\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec.load(\"../models/210330_word2vec.model\")\n",
    "\n",
    "print(model.wv.similarity(\"晶圓\", \"價值\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.wv.most_similar([\"晶圓\", \"矽\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monpa",
   "language": "python",
   "name": "monpa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
