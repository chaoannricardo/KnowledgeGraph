{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hired-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-celebration",
   "metadata": {},
   "source": [
    "# Some Reference\n",
    "\n",
    "* Regular Expression Tester: https://regex101.com/\n",
    "* Some Re Tutorials: https://medium.com/factory-mind/regex-tutorial-a-simple-cheatsheet-by-examples-649dc1c3f285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fluid-metadata",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Windows_Storage\\Storage\\Github\\KnowledgeGraph\\scripts\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "distinguished-affiliate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7253\n",
      "  Segmented Element   POS  Dependecies\n",
      "0              第二十三   NUM       nummod\n",
      "1                 章   NUM     mark:clf\n",
      "2                半導  NOUN  compound:nn\n",
      "3                體製  NOUN  compound:nn\n",
      "4                造概  NOUN  compound:nn\n"
     ]
    }
   ],
   "source": [
    "# read in tokens\n",
    "\n",
    "# dataToken = pd.read_csv(\"../results/矽晶圓製造業資源化應用技術手冊_monpaResult.csv\", encoding=\"utf8\")\n",
    "dataToken = pd.read_csv(\"../results/第二十三章半導體製造概論_spaCyResult.csv\", encoding=\"utf8\")\n",
    "\n",
    "# append a column for data if dependencies column does not exist (monpa case)\n",
    "if len(dataToken.columns) < 3:\n",
    "    dataToken.loc[:, \"Dependecies\"] = np.nan\n",
    "\n",
    "print(len(dataToken))\n",
    "print(dataToken.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aggressive-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONPA\n",
    "# relation_dependencies_possible_list = []\n",
    "# relation_pos_possible_list = [\"VH\", \"VC\", \"VJ\", \"VA\"]\n",
    "# relation_pos_re = \"^[V]\"\n",
    "# entity_dependencies_possible_list = []\n",
    "# entity_pos_possible_list = [\"Na\", \"Nv\", \"Neu\", \"Nes\", \"Nf\", \"Ng\", \"Nh\", \"Neqa\", \"Nep\", \"Ncd\", \"FW\", \"DE\"]\n",
    "# entity_pos_re = \"^[N]\"\n",
    "# bracket_pos_list = [\"PARENTHESISCATEGORY\"]\n",
    "# punct_pos_list = [\"COMMACATEGORY\", \"PERIODCATEGORY\"]\n",
    "\n",
    "# spaCy\n",
    "relation_dependencies_possible_list = [\"ROOT\", \"nmod:prep\", \"prep\", \"agent\", ]\n",
    "relation_pos_possible_list = [\"VERB\"]\n",
    "relation_pos_re = \"^[V]\"\n",
    "entity_dependencies_possible_list = [\"compound:nn\", \"nsubj\", \"dep\", \"dobj\"]\n",
    "entity_pos_possible_list = [\"NOUN\", \"PROPN\"]\n",
    "entity_pos_re = \"^[N]\"\n",
    "bracket_pos_list = []\n",
    "punct_pos_list = [\"PUNCT\"]\n",
    "\n",
    "# Common, usually entity\n",
    "sentences_splitter = [\"，\", \"。\", \"！\", \"!\", \"？\", \"?\"]\n",
    "bracket_entity_list = [\"(\", \")\", \"（\", \"）\"]\n",
    "punct_entity_list = [\" \" * i for i in range(0, 100)]\n",
    "conjuction_entity_list = [\"的\", \"、\", \"之\", \"及\", \"與\"]\n",
    "not_entity_relation_list = [\"的\", \"、\", \"之\", \"及\", \"與\", \"\\r\\n \\r\\n \", \"\\r\\n \\r\\n  \"] +\\\n",
    "[\" \" * i for i in range(0, 100)] + [\"\\n\" * i for i in range(0, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "everyday-beast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list length (Sentences):  580 580 580\n",
      "['章', '半導', '體製', '造概', '\\r\\n \\r\\n', '第二十三', '章', '半導', '體製', '造概', '\\r\\n \\r\\n', '近幾'] ['NUM', 'NOUN', 'NOUN', 'NOUN', 'PUNCT', 'SPACE', 'NUM', 'NUM', 'NOUN', 'NOUN', 'NOUN', 'PUNCT', 'SPACE', 'ADV', 'PUNCT'] ['mark:clf', 'compound:nn', 'compound:nn', 'compound:nn', 'nmod:topic', 'punct', 'nummod', 'mark:clf', 'compound:nn', 'compound:nn', 'compound:nn', 'nsubj', 'punct', 'advmod', 'punct']\n",
      "list length:  580 580 580\n"
     ]
    }
   ],
   "source": [
    "# devide token by seperators\n",
    "total_entity_list = []\n",
    "sentence_entity_list = []\n",
    "total_label_list = []\n",
    "sentence_label_list = []\n",
    "total_dependencies_list = []\n",
    "sentence_dependencies_list = []\n",
    "\n",
    "\n",
    "# devide tokens by chinese punctuations\n",
    "for index, entityElement in enumerate(dataToken.iloc[:, 0]):\n",
    "    if entityElement not in sentences_splitter:\n",
    "        sentence_entity_list.append(entityElement)\n",
    "        sentence_label_list.append(dataToken.iloc[index, 1])\n",
    "        sentence_dependencies_list.append(dataToken.iloc[index, 2])\n",
    "    else:\n",
    "        total_entity_list.append(sentence_entity_list)\n",
    "        total_label_list.append(sentence_label_list)\n",
    "        total_dependencies_list.append(sentence_dependencies_list)\n",
    "        sentence_entity_list = []\n",
    "        sentence_label_list = []\n",
    "        sentence_dependencies_list = []\n",
    "    \n",
    "print(\"list length (Sentences): \", len(total_entity_list), len(total_label_list), len(total_dependencies_list))\n",
    "\n",
    "\n",
    "# Clean up tokens and eliminate unneccesary tokens\n",
    "for sentenceIndex, sentences in enumerate(total_entity_list):\n",
    "    indexPunct_0 = 0\n",
    "    indexPunct_1 = 0\n",
    "    for tokenIndex, tokens in enumerate(sentences):\n",
    "        # set up element indexes that are between two punctuation\n",
    "        if total_label_list[sentenceIndex][tokenIndex] in bracket_pos_list or sentences[tokenIndex] in bracket_entity_list:\n",
    "            if indexPunct_0 == 0:\n",
    "                indexPunct_0 = tokenIndex\n",
    "            else:\n",
    "                indexPunct_1 = tokenIndex\n",
    "        elif total_label_list[sentenceIndex][tokenIndex] in punct_pos_list or sentences[tokenIndex] in punct_entity_list:\n",
    "            # set token that fit certain POS type to \"\"\n",
    "            total_entity_list[sentenceIndex][tokenIndex] = \"\"\n",
    "            \n",
    "    # remove tokens that are between two punctuations, and certain POS type\n",
    "    if indexPunct_1 == 0:\n",
    "        total_entity_list[sentenceIndex][indexPunct_1] = \"\"\n",
    "        total_label_list[sentenceIndex][indexPunct_1] = \"\"\n",
    "        total_dependencies_list[sentenceIndex][indexPunct_1] = \"\"\n",
    "    else:\n",
    "        for removeIndex in range(indexPunct_0, indexPunct_1 + 1):\n",
    "            total_entity_list[sentenceIndex][removeIndex] = \"\"\n",
    "            total_label_list[sentenceIndex][removeIndex] = \"\"\n",
    "            total_dependencies_list[sentenceIndex][removeIndex] = \"\"\n",
    "            \n",
    "    total_entity_list[sentenceIndex] = list(filter((\"\").__ne__, total_entity_list[sentenceIndex]))\n",
    "    total_label_list[sentenceIndex]  = list(filter((\"\").__ne__, total_label_list[sentenceIndex]))\n",
    "    total_dependencies_list[sentenceIndex] = list(filter((\"\").__ne__, total_dependencies_list[sentenceIndex]))\n",
    "                \n",
    "print(total_entity_list[0] , total_label_list[0], total_dependencies_list[0])\n",
    "print(\"list length: \", len(total_entity_list), len(total_label_list), len(total_dependencies_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pretty-donor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580 580 580 580\n",
      "['章半導體製造概', '章半導體製造概\\r\\n \\r\\n近幾'] [3, 11] [] []\n",
      "['電子科技', '等', ''] [1, 3, 6] [] []\n",
      "['全球電子市場消費水準的提昇'] [6] ['提昇'] [6]\n",
      "['電腦', '工作站', '通信', '設備', '電子', '', '激增'] [0, 2, 4, 6, 8, 10, 12] [] []\n",
      "['世界半導體產業', '發展'] [4, 6] [] []\n",
      "['台灣'] [1] ['台灣'] [1]\n",
      "['業更', '國家經濟動脈的一個主力'] [0, 10] ['成為', '維繫'] [2, 3]\n",
      "['半導體製造為一', '直分工細', '高', '價值的產業'] [3, 6, 8, 12] ['造為', '工細', '密且', '產業'] [2, 6, 7, 12]\n",
      "['成長', '週邊產業的繁榮'] [2, 10] ['快速', '會', '帶動'] [0, 4, 5]\n",
      "['一', '半導體產業體系架構'] [2, 9] ['示為', '典型', '架構'] [1, 3, 9]\n",
      "['體系'] [1] ['體系'] [1]\n",
      "[] [] [] []\n",
      "['就是', '晶圓加工'] [1, 7] ['稱'] [4]\n",
      "['資', '技術', '處'] [0, 2, 7] ['密集'] [5]\n",
      "['著晶圓加工的上游產業則', '產品設計製造'] [7, 11] ['伴隨', '包括'] [0, 8]\n"
     ]
    }
   ],
   "source": [
    "# get entity pairs and relations\n",
    "\n",
    "# get relations\n",
    "all_relations_list = []\n",
    "all_relations_index = []\n",
    "all_element_flatten = []\n",
    "all_relation_flatten = []\n",
    "\n",
    "for sentenceIndex, sentences in enumerate(total_entity_list):\n",
    "    relation_list = []\n",
    "    relation_index_list = []\n",
    "    for tokenIndex, token in enumerate(sentences):\n",
    "        if len(sentences) > 1: \n",
    "            if total_dependencies_list[sentenceIndex][tokenIndex] in relation_dependencies_possible_list or\\\n",
    "            total_label_list[sentenceIndex][tokenIndex] in relation_pos_possible_list or\\\n",
    "            re.match(relation_pos_re, str(total_label_list[sentenceIndex][tokenIndex]), flags=re.IGNORECASE) != None:\n",
    "                relation_list.append(token)\n",
    "                relation_index_list.append(tokenIndex)\n",
    "    all_relations_list.append(relation_list)\n",
    "    all_relations_index.append(relation_index_list)\n",
    "\n",
    "\n",
    "# get entities\n",
    "all_reformatted_entities = []\n",
    "all_reformatted_index_list = []\n",
    "for sentenceIndex, sentences in enumerate(total_entity_list):\n",
    "    entity_index_list = []\n",
    "    possible_entities = []\n",
    "    reformatted_entities = []\n",
    "    reformatted_index_list = []\n",
    "    for tokenIndex, token in enumerate(sentences):\n",
    "        if len(sentences) > 1:\n",
    "            if total_dependencies_list[sentenceIndex][tokenIndex] in entity_dependencies_possible_list or\\\n",
    "            total_label_list[sentenceIndex][tokenIndex] in entity_pos_possible_list or\\\n",
    "            re.match(entity_pos_re, str(total_label_list[sentenceIndex][tokenIndex]), flags=re.IGNORECASE) != None or\\\n",
    "            token in conjuction_entity_list:\n",
    "                entity_index_list.append(tokenIndex)\n",
    "                possible_entities.append(token)\n",
    "    # combine token if situate next to each other\n",
    "#     print(entity_index_list, possible_entities)\n",
    "    if len(possible_entities) > 0:\n",
    "        combine_entity_name = possible_entities[0]\n",
    "        for possibleIndex, possibleElement in enumerate(entity_index_list):\n",
    "#             print(possible_entities)\n",
    "            \n",
    "            isContinuous = False\n",
    "            if possibleIndex != 0:\n",
    "                if possibleElement == entity_index_list[possibleIndex - 1] + 1:\n",
    "                    isContinuous = True\n",
    "                    combine_entity_name += possible_entities[possibleIndex]\n",
    "                else:\n",
    "                    isContinuous = False\n",
    "            \n",
    "                if isContinuous == False:\n",
    "                    reformatted_entities.append(combine_entity_name)\n",
    "                    reformatted_index_list.append(entity_index_list[possibleIndex-1])\n",
    "                    combine_entity_name = possible_entities[possibleIndex]\n",
    "                    \n",
    "            if possibleIndex == (len(entity_index_list) - 1):\n",
    "                reformatted_entities.append(combine_entity_name)\n",
    "                reformatted_index_list.append(possibleElement)\n",
    "                \n",
    "#             print(combine_entity_name)     \n",
    "#     print(reformatted_entities)\n",
    "    all_reformatted_entities.append(reformatted_entities)\n",
    "    all_reformatted_index_list.append(reformatted_index_list)\n",
    "    \n",
    "# flatten section\n",
    "# remove unneccessary conjuction words\n",
    "for index, element in enumerate(all_reformatted_entities):\n",
    "    \n",
    "    for elementIndex, elementSingle in enumerate(element):\n",
    "        # remove single conjuction char in first or last position\n",
    "        if elementSingle[0] in conjuction_entity_list:\n",
    "            element[elementIndex] = elementSingle[1:]\n",
    "        elif elementSingle[-1] in conjuction_entity_list:\n",
    "            element[elementIndex] = elementSingle[:-1]\n",
    "            \n",
    "        all_element_flatten.append(element[elementIndex])\n",
    "        \n",
    "    for relationIndex, relationSingle in enumerate(all_relations_list[index]):\n",
    "        # remove single conjuction char in first or last position\n",
    "        if relationSingle[0] in conjuction_entity_list:\n",
    "            all_relations_list[index][relationIndex] = relationSingle[1:]\n",
    "        elif relationSingle[-1] in conjuction_entity_list:\n",
    "            all_relations_list[index][relationIndex] = relationSingle[:-1]\n",
    "            \n",
    "        all_relation_flatten.append(all_relations_list[index][relationIndex])\n",
    "                      \n",
    "        \n",
    "# print(all_relations_list, len(all_relations_list), \"\\n\")\n",
    "# print(all_reformatted_entities, len(all_reformatted_entities), )\n",
    "print(len(all_relations_list), len(all_relations_index), len(all_reformatted_entities), len(all_reformatted_index_list))\n",
    "\n",
    "# print out parsing result\n",
    "for index, element in enumerate(all_reformatted_entities[:15]):\n",
    "    print(element, all_reformatted_index_list[index], all_relations_list[index], all_relations_index[index])\n",
    "    \n",
    "data_result = pd.DataFrame({\n",
    "    \"Entity\":all_reformatted_entities,\n",
    "    \"EntityIndex\":all_reformatted_index_list,\n",
    "    \"Relation\":all_relations_list,\n",
    "    \"RelationIndex\":all_relations_index\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advisory-australian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1090    Entity  Count  Ratio\n",
      "0      測品     17  2.09%\n",
      "1      晶片     11  1.35%\n",
      "2      產品      8  0.98%\n",
      "3       其      8  0.98%\n",
      "4      封裝      7  0.86%\n",
      "5    測試機台      7  0.86%\n",
      "6      晶圓      6  0.74%\n",
      "7       等      6  0.74%\n",
      "8    測試程式      6  0.74%\n",
      "9       一      6  0.74%\n",
      "10     過程      6  0.74%\n",
      "11     電路      6  0.74%\n",
      "12     技術      6  0.74%\n",
      "13      二      6  0.74%\n",
      "14     製程      5  0.61%\n",
      "15     不同      5  0.61%\n",
      "16     成品      5  0.61%\n",
      "17      三      5  0.61%\n",
      "18     引腳      5  0.61%\n",
      "19     晶粒      5  0.61% \n",
      "\n",
      "1101       Relation  Count  Ratio\n",
      "0            有     35  5.72%\n",
      "1            是     32  5.23%\n",
      "2            可     16  2.61%\n",
      "3           測試     15  2.45%\n",
      "4           提供     14  2.29%\n",
      "5    \\r\\n \\r\\n     13  2.12%\n",
      "6            為     12  1.96%\n",
      "7           進行     12  1.96%\n",
      "8            要     12  1.96%\n",
      "9           完成     12  1.96%\n",
      "10          需要     10  1.63%\n",
      "11          可以     10  1.63%\n",
      "12          封裝     10  1.63%\n",
      "13          不同      9  1.47%\n",
      "14           在      8  1.31%\n",
      "15           會      8  1.31%\n",
      "16           能      8  1.31%\n",
      "17           一      7  1.14%\n",
      "18          晶圓      7  1.14%\n",
      "19          包括      7  1.14%\n"
     ]
    }
   ],
   "source": [
    "# conculde a list with frequency\n",
    "        \n",
    "for notIndex, notElement in enumerate(not_entity_relation_list):\n",
    "    all_element_flatten = list(filter((notElement).__ne__, all_element_flatten))\n",
    "    all_relation_flatten = list(filter((notElement).__ne__, all_relation_flatten))\n",
    "        \n",
    "data_entity = pd.DataFrame({\n",
    "    \"Entity\":all_element_flatten,\n",
    "})\n",
    "\n",
    "data_relation = pd.DataFrame({\n",
    "    \"Relation\":all_relation_flatten,\n",
    "})\n",
    "\n",
    "def ratiolize(x):\n",
    "    x = str(np.around(x * 100, decimals=2)) + \"%\"\n",
    "    return x\n",
    "\n",
    "data_entity_value_count = data_entity.value_counts(ascending=False).to_frame()\n",
    "data_entity_value_count.reset_index(inplace=True)\n",
    "data_entity_value_count = data_entity_value_count.rename(columns = {'index':'Entity'})\n",
    "data_entity_value_count = data_entity_value_count.rename(columns = {0:'Count'})\n",
    "data_entity_value_count.loc[:, \"Ratio\"] = data_entity_value_count.iloc[:, 1] / len(data_entity_value_count)\n",
    "data_entity_value_count.loc[:, \"Ratio\"] = data_entity_value_count.loc[:, \"Ratio\"].apply(ratiolize)\n",
    "\n",
    "data_relation_value_count = data_relation.value_counts(ascending=False).to_frame()\n",
    "data_relation_value_count.reset_index(inplace=True)\n",
    "data_relation_value_count = data_relation_value_count.rename(columns = {'index':'Relation'})\n",
    "data_relation_value_count = data_relation_value_count.rename(columns = {0:'Count'})\n",
    "data_relation_value_count.loc[:, \"Ratio\"] = data_relation_value_count.iloc[:, 1] / len(data_relation_value_count)\n",
    "data_relation_value_count.loc[:, \"Ratio\"] = data_relation_value_count.loc[:, \"Ratio\"].apply(ratiolize)\n",
    "\n",
    "print(len(data_entity), data_entity_value_count[:20], \"\\n\")\n",
    "print(len(data_relation), data_relation_value_count[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "italic-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_entity_value_count.to_csv(\"../results/第二十三章半導體製造概論_entity_result_spaCy.csv\", encoding=\"utf8\", index=None)\n",
    "data_relation_value_count.to_csv(\"../results/第二十三章半導體製造概論_relation_result_spaCy.csv\", encoding=\"utf8\", index=None)\n",
    "data_result.to_csv(\"../results/第二十三章半導體製造概論_main_result_spaCy.csv\", encoding=\"utf8\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-geography",
   "metadata": {},
   "source": [
    "# Filter out most frequent edge and relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "sonic-facing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Entity  \\\n",
      "0     ['製造業資源', '應用技術手冊', '：經濟部工業局出版', '96 年8 月     ...   \n",
      "10    ['動', '棄 物', ' 源 化是', '向', '際 ', ' 永 續 經', '',...   \n",
      "16    [' 晶 圓製 造 ', '各類廢 棄', '資 源', '實 際 執 ', '情 形 彙整...   \n",
      "22    ['謝 朝 陽 科 技 大 學 環 境 工 程 與 管 理系 王 文 裕 助', ' 教 授...   \n",
      "28    ['  謹 識   ', '年8 月I  目 錄    頁碼第一章 前言', '1', ' ...   \n",
      "...                                                 ...   \n",
      "2871                         ['有機溶劑', '', '生產', '純化方法']   \n",
      "2876                            ['廢溶劑', '處理技術與案例', '＂']   \n",
      "2884                           ['有機溶劑', '', '生產', '方法']   \n",
      "2894         ['リコソウエハ', '工程で', 'されゐ', '酸', 'らの酸の分離．回收']   \n",
      "2896    ['28   矽晶圓製造業資源', '應用技術手冊/', '生產力', '編', '臺北市']   \n",
      "\n",
      "                                            EntityIndex  \\\n",
      "0            [1, 5, 12, 18, 22, 25, 27, 30, 37, 39, 43]   \n",
      "10                         [0, 3, 7, 9, 11, 15, 17, 23]   \n",
      "16                                  [6, 11, 13, 18, 24]   \n",
      "22    [13, 18, 25, 30, 43, 50, 53, 55, 57, 59, 61, 6...   \n",
      "28    [3, 12, 14, 19, 21, 27, 39, 41, 45, 49, 60, 71...   \n",
      "...                                                 ...   \n",
      "2871                                       [1, 3, 5, 8]   \n",
      "2876                                          [0, 5, 7]   \n",
      "2884                                       [1, 3, 5, 8]   \n",
      "2894                                 [5, 9, 13, 15, 22]   \n",
      "2896                                 [4, 9, 15, 17, 23]   \n",
      "\n",
      "                                               Relation  \\\n",
      "0                                ['化', ' 計', '製', 'IC']   \n",
      "10                  ['廢 ', ' 資', ' 邁 ', '', ' 營', '施 ']   \n",
      "16                        ['將', '業 ', ' 物', ' 化', '行 ']   \n",
      "22                  [' 參 ', '撰', '大 ', '工 ', '技 ', '等']   \n",
      "28    ['廢棄物', '5.2', '.................................   \n",
      "...                                                 ...   \n",
      "2871                                  ['回收', '清潔', '－']   \n",
      "2876                                       ['回收', '探討']   \n",
      "2884                            ['廢', '回收', '清潔', '純化']   \n",
      "2894                             ['製造', '排出', '廢', 'か']   \n",
      "2896                           ['化', '基金會', '--', '臺灣']   \n",
      "\n",
      "                                          RelationIndex  \n",
      "0                                       [2, 26, 31, 38]  \n",
      "10                                [1, 4, 8, 13, 16, 21]  \n",
      "16                                   [1, 7, 12, 14, 19]  \n",
      "22                             [46, 54, 56, 60, 78, 88]  \n",
      "28    [46, 106, 119, 121, 131, 156, 170, 180, 182, 1...  \n",
      "...                                                 ...  \n",
      "2871                                          [2, 4, 6]  \n",
      "2876                                             [1, 6]  \n",
      "2884                                       [0, 2, 4, 7]  \n",
      "2894                                    [7, 10, 14, 16]  \n",
      "2896                                    [5, 16, 19, 30]  \n",
      "\n",
      "[629 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "data_entity_value_count = pd.read_csv(\"../results/矽晶圓製造業資源化應用技術手冊_entity_result_spaCy.csv\", encoding=\"utf8\")\n",
    "data_relation_value_count = pd.read_csv(\"../results/矽晶圓製造業資源化應用技術手冊_relation_result_spaCy.csv\", encoding=\"utf8\")\n",
    "data_result = pd.read_csv(\"../results/矽晶圓製造業資源化應用技術手冊_main_result_spaCy.csv\", encoding=\"utf8\")\n",
    "\n",
    "# take only first 20 places\n",
    "data_entity_filter = data_entity_value_count.loc[:, \"Entity\"].tolist()[:20]\n",
    "data_relation_filter = data_relation_value_count.loc[:, \"Relation\"].tolist()[:20]\n",
    "\n",
    "abandonIndexList = []\n",
    "\n",
    "for rowIndex, rowItem in enumerate(data_result.iloc[:, 0]):\n",
    "    need_to_abandon = True\n",
    "    entityList = rowItem.replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")[:-1]\n",
    "    relationList = data_result.iloc[rowIndex, 2].replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")[:-1]\n",
    "    \n",
    "    for entityIndex, entityElement in enumerate(entityList):\n",
    "        if entityElement in data_entity_filter:\n",
    "            need_to_abandon = False\n",
    "            break\n",
    "    \n",
    "    for relationIndex, relationElement in enumerate(relationList):\n",
    "        if need_to_abandon == False:\n",
    "            break\n",
    "        if relationElement in data_relation_filter:\n",
    "            need_to_abandon = False\n",
    "            break\n",
    "            \n",
    "    if need_to_abandon == True:\n",
    "        abandonIndexList.append(rowIndex)\n",
    "            \n",
    "data_result.drop(index=abandonIndexList, inplace=True)\n",
    "print(data_result)\n",
    "\n",
    "# export data\n",
    "data_result.to_csv(\"../results/矽晶圓製造業資源化應用技術手冊_filter_result_spaCy.csv\", encoding=\"utf8\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monpa",
   "language": "python",
   "name": "monpa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
