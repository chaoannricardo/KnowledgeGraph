{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a96a9962-e070-49ef-a152-34d76f76264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 17:44:50 INFO: \"zh\" is an alias for \"zh-hans\"\n",
      "2021-05-05 17:44:50 INFO: Loading these models for language: zh-hans (Simplified_Chinese):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | ../../../K...ize/gsd.pt |\n",
      "| pos       | ../../../K...pos/gsd.pt |\n",
      "| lemma     | ../../../K...mma/gsd.pt |\n",
      "| depparse  | ../../../K...rse/gsd.pt |\n",
      "=======================================\n",
      "\n",
      "2021-05-05 17:44:50 INFO: Use device: gpu\n",
      "2021-05-05 17:44:50 INFO: Loading: tokenize\n",
      "2021-05-05 17:44:50 INFO: Loading: pos\n",
      "2021-05-05 17:44:50 INFO: Loading: lemma\n",
      "2021-05-05 17:44:50 INFO: Loading: depparse\n",
      "2021-05-05 17:44:51 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "# stanza.download('zh-hant')\n",
    "\n",
    "config = {\n",
    "    'processors': 'tokenize,pos,lemma,depparse', # Comma-separated list of processors to use\n",
    "    'lang': 'zh', # Language code for the language to build the Pipeline in\n",
    "    'tokenize_model_path': '../../../KnowledgeGraph_materials/stanza_resources/zh-hant/tokenize/gsd.pt', # Processor-specific arguments are set with keys \"{processor_name}_{argument_name}\"\n",
    "    'pos_model_path': '../../../KnowledgeGraph_materials/stanza_resources/zh-hant/pos/gsd.pt',\n",
    "    'pos_pretrain_path':'../../../KnowledgeGraph_materials/stanza_resources/zh-hant/pretrain/gsd.pt',\n",
    "    'lemma_model_path': '../../../KnowledgeGraph_materials/stanza_resources/zh-hant/lemma/gsd.pt',\n",
    "    'depparse_model_path': '../../../KnowledgeGraph_materials/stanza_resources/zh-hant/depparse/gsd.pt',\n",
    "    'depparse_pretrain_path': '../../../KnowledgeGraph_materials/stanza_resources/zh-hant/pretrain/gsd.pt',\n",
    "}\n",
    "\n",
    "nlp = stanza.Pipeline(**config) # Initialize the pipeline using a configuration dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97175b36-7d95-443f-9a9b-864ef60adf48",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc489881-a0a8-4cc3-adc2-3a740689abbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-06 02:01:59 INFO: \"zh\" is an alias for \"zh-hans\"\n",
      "2021-05-06 02:01:59 INFO: Loading these models for language: zh-hans (Simplified_Chinese):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | ../../../K...ize/gsd.pt |\n",
      "| pos       | ../../../K...pos/gsd.pt |\n",
      "| lemma     | ../../../K...mma/gsd.pt |\n",
      "| depparse  | ../../../K...rse/gsd.pt |\n",
      "=======================================\n",
      "\n",
      "2021-05-06 02:01:59 INFO: Use device: gpu\n",
      "2021-05-06 02:01:59 INFO: Loading: tokenize\n",
      "2021-05-06 02:01:59 INFO: Loading: pos\n",
      "2021-05-06 02:02:00 INFO: Loading: lemma\n",
      "2021-05-06 02:02:00 INFO: Loading: depparse\n",
      "2021-05-06 02:02:00 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "# stanza.download('zh-hant')\n",
    "\n",
    "config = {\n",
    "    'processors': 'tokenize,pos,lemma,depparse', # Comma-separated list of processors to use\n",
    "    'lang': 'zh', # Language code for the language to build the Pipeline in\n",
    "    'tokenize_model_path': '../../../KnowledgeGraph_materials/stanza_resources/zh-hant/tokenize/gsd.pt', # Processor-specific arguments are set with keys \"{processor_name}_{argument_name}\"\n",
    "    'pos_model_path': '../../../KnowledgeGraph_materials/stanza_resources/zh-hant/pos/gsd.pt',\n",
    "    'pos_pretrain_path':'../../../KnowledgeGraph_materials/stanza_resources/zh-hant/pretrain/gsd.pt',\n",
    "    'lemma_model_path': '../../../KnowledgeGraph_materials/stanza_resources/zh-hant/lemma/gsd.pt',\n",
    "    'depparse_model_path': '../../../KnowledgeGraph_materials/stanza_resources/zh-hant/depparse/gsd.pt',\n",
    "    'depparse_pretrain_path': '../../../KnowledgeGraph_materials/stanza_resources/zh-hant/pretrain/gsd.pt',\n",
    "}\n",
    "\n",
    "nlp = stanza.Pipeline(**config) # Initialize the pipeline using a configuration dict\n",
    "\n",
    "# doc = nlp(\"古往今來，能飾演古龍小說人物楚留香的，無一不是娛樂圈公認的美男子，2011年，36歲的張智堯在，楚留香新傳，裡飾演楚留香，依舊帥得讓人無法自拔\")\n",
    "# print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7233087-66f1-4d4a-bec8-f062a5991623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1 word: 古 head id: 2 head: 埃及 deprel: case:pref\n",
      "id: 2 word: 埃及 head id: 14 head: 開始 deprel: nsubj\n",
      "id: 3 word: 、 head id: 4 head: 西南亞 deprel: punct\n",
      "id: 4 word: 西南亞 head id: 2 head: 埃及 deprel: conj\n",
      "id: 5 word: 、 head id: 6 head: 南歐 deprel: punct\n",
      "id: 6 word: 南歐 head id: 2 head: 埃及 deprel: conj\n",
      "id: 7 word: 、 head id: 8 head: 中歐 deprel: punct\n",
      "id: 8 word: 中歐 head id: 2 head: 埃及 deprel: conj\n",
      "id: 9 word: 和 head id: 10 head: 中國 deprel: cc\n",
      "id: 10 word: 中國 head id: 2 head: 埃及 deprel: conj\n",
      "id: 11 word: 等 head id: 2 head: 埃及 deprel: acl\n",
      "id: 12 word: 地 head id: 2 head: 埃及 deprel: appos\n",
      "id: 13 word: 先後 head id: 14 head: 開始 deprel: advmod\n",
      "id: 14 word: 開始 head id: 0 head: root deprel: root\n",
      "id: 15 word: 用 head id: 14 head: 開始 deprel: xcomp\n",
      "id: 16 word: 礦石 head id: 17 head: 煉銅 deprel: nmod\n",
      "id: 17 word: 煉銅 head id: 15 head: 用 deprel: obj\n",
      "id: 18 word: 。 head id: 14 head: 開始 deprel: punct\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"古埃及、西南亞、南歐、中歐和中國等地先後開始用礦石煉銅。\")\n",
    "\n",
    "\n",
    "\n",
    "# for token in doc:\n",
    "#     for child in token.children:\n",
    "#         # append token to construct graph\n",
    "#         edges.append(('{0}'.format(token.lower_),\n",
    "#                               '{0}'.format(child.lower_)))\n",
    "#         edges_and_dependencies.append(('{0}'.format((token.lower_, token.dep_)),\n",
    "#                                                '{0}'.format((child.lower_, child.dep_))))\n",
    "        \n",
    "        \n",
    "for sent in doc.sentences:\n",
    "    for word in sent.words:\n",
    "        print(f\"id: {word.id}\", f\"word: {word.text}\", f\"head id: {word.head}\", \n",
    "              f\"head: {sent.words[word.head-1].text if word.head > 0 else 'root'}\", f\"deprel: {word.deprel}\")\n",
    "        edges.append(('{0}'.format(word.id),\n",
    "                              '{0}'.format(word.head)))\n",
    "\n",
    "\n",
    "# # append data for graph searching\n",
    "# edges_list.append(str(token))\n",
    "# dependencies_list.append(token.dep_)\n",
    "\n",
    "    \n",
    "# print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c005aab5-9d99-4b26-85de-2ebfb5569eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: 中國\tupos: PROPN\txpos: NNP\tfeats: _\n",
      "word: 二里岡\tupos: PROPN\txpos: NNP\tfeats: _\n",
      "word: 文化\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 存在\tupos: VERB\txpos: VV\tfeats: _\n",
      "word: 。\tupos: PUNCT\txpos: .\tfeats: _\n",
      "word: 古代\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 埃及\tupos: PROPN\txpos: NNP\tfeats: _\n",
      "word: 人\tupos: PART\txpos: SFN\tfeats: _\n",
      "word: 已\tupos: ADV\txpos: RB\tfeats: _\n",
      "word: 使用\tupos: VERB\txpos: VV\tfeats: _\n",
      "word: 24\tupos: NUM\txpos: CD\tfeats: NumType=Card\n",
      "word: 個\tupos: NOUN\txpos: NNB\tfeats: _\n",
      "word: 字母\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 符號\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 。\tupos: PUNCT\txpos: .\tfeats: _\n",
      "word: 古代\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 埃及\tupos: PROPN\txpos: NNP\tfeats: _\n",
      "word: 小說\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 《\tupos: PUNCT\txpos: (\tfeats: _\n",
      "word: 錫諾赫\tupos: PROPN\txpos: NNP\tfeats: _\n",
      "word: 的\tupos: PART\txpos: DEC\tfeats: Case=Gen\n",
      "word: 故事\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 》\tupos: PUNCT\txpos: )\tfeats: _\n",
      "word: 問世\tupos: VERB\txpos: VV\tfeats: _\n",
      "word: 。\tupos: PUNCT\txpos: .\tfeats: _\n",
      "word: 古巴比倫\tupos: PROPN\txpos: NNP\tfeats: _\n",
      "word: 人\tupos: PART\txpos: SFN\tfeats: _\n",
      "word: 創造\tupos: VERB\txpos: VV\tfeats: _\n",
      "word: 了\tupos: PART\txpos: AS\tfeats: Aspect=Perf\n",
      "word: 發達\tupos: ADJ\txpos: JJ\tfeats: _\n",
      "word: 的\tupos: PART\txpos: DEC\tfeats: _\n",
      "word: 數學\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 和\tupos: CCONJ\txpos: CC\tfeats: _\n",
      "word: 天文\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 學\tupos: PART\txpos: SFN\tfeats: _\n",
      "word: 。\tupos: PUNCT\txpos: .\tfeats: _\n",
      "word: 馬\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 開始\tupos: VERB\txpos: VV\tfeats: _\n",
      "word: 用\tupos: VERB\txpos: VV\tfeats: _\n",
      "word: 於\tupos: VERB\txpos: VV\tfeats: _\n",
      "word: 車輛\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 運輸\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 。\tupos: PUNCT\txpos: .\tfeats: _\n",
      "word: 英國\tupos: PROPN\txpos: NNP\tfeats: _\n",
      "word: 索爾茲伯裡\tupos: PROPN\txpos: NNP\tfeats: _\n",
      "word: 和\tupos: CCONJ\txpos: CC\tfeats: _\n",
      "word: 威爾特\tupos: PROPN\txpos: NNP\tfeats: _\n",
      "word: 地區\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 建造\tupos: VERB\txpos: VV\tfeats: _\n",
      "word: 史\tupos: PART\txpos: SFN\tfeats: _\n",
      "word: 前\tupos: PART\txpos: PFA\tfeats: _\n",
      "word: 巨石\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 群\tupos: PART\txpos: SFN\tfeats: _\n",
      "word: 。\tupos: PUNCT\txpos: .\tfeats: _\n",
      "word: 古\tupos: PART\txpos: PFA\tfeats: _\n",
      "word: 埃及\tupos: PROPN\txpos: NNP\tfeats: _\n",
      "word: 人\tupos: PART\txpos: SFN\tfeats: _\n",
      "word: 已\tupos: ADV\txpos: RB\tfeats: _\n",
      "word: 使用\tupos: VERB\txpos: VV\tfeats: _\n",
      "word: 水\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 銀\tupos: PART\txpos: SFN\tfeats: _\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"中國二里岡文化存在。古代埃及人已使用24個字母符號。古代埃及小說《錫諾赫的故事》問世。古巴比倫人創造了發達的數學和天文學。馬開始用於車輛運輸。英國索爾茲伯裡和威爾特地區建造史前巨石群。古埃及人已使用水銀\")\n",
    "\n",
    "print(*[f'word: {word.text}\\tupos: {word.upos}\\txpos: {word.xpos}\\tfeats: {word.feats if word.feats else \"_\"}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
