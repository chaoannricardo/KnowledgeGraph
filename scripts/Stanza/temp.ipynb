{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a96a9962-e070-49ef-a152-34d76f76264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-20 10:52:33 INFO: \"zh\" is an alias for \"zh-hans\"\n",
      "2021-05-20 10:52:33 INFO: Loading these models for language: zh-hans (Simplified_Chinese):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | ../../../K...ize/gsd.pt |\n",
      "| pos       | ../../../K...pos/gsd.pt |\n",
      "| lemma     | ../../../K...mma/gsd.pt |\n",
      "| depparse  | ../../../K...rse/gsd.pt |\n",
      "=======================================\n",
      "\n",
      "2021-05-20 10:52:33 INFO: Use device: gpu\n",
      "2021-05-20 10:52:33 INFO: Loading: tokenize\n",
      "2021-05-20 10:52:35 INFO: Loading: pos\n",
      "2021-05-20 10:52:35 INFO: Loading: lemma\n",
      "2021-05-20 10:52:35 INFO: Loading: depparse\n",
      "2021-05-20 10:52:36 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "# stanza.download('zh-hant')\n",
    "\n",
    "config = {\n",
    "    'processors': 'tokenize,pos,lemma,depparse', # Comma-separated list of processors to use\n",
    "    'lang': 'zh', # Language code for the language to build the Pipeline in\n",
    "    'tokenize_model_path': '../../../KnowledgeGraph_materials/stanza_resources/zh-hant/tokenize/gsd.pt', # Processor-specific arguments are set with keys \"{processor_name}_{argument_name}\"\n",
    "    'pos_model_path': '../../../KnowledgeGraph_materials/stanza_resources/zh-hant/pos/gsd.pt',\n",
    "    'pos_pretrain_path':'../../../KnowledgeGraph_materials/stanza_resources/zh-hant/pretrain/gsd.pt',\n",
    "    'lemma_model_path': '../../../KnowledgeGraph_materials/stanza_resources/zh-hant/lemma/gsd.pt',\n",
    "    'depparse_model_path': '../../../KnowledgeGraph_materials/stanza_resources/zh-hant/depparse/gsd.pt',\n",
    "    'depparse_pretrain_path': '../../../KnowledgeGraph_materials/stanza_resources/zh-hant/pretrain/gsd.pt',\n",
    "}\n",
    "\n",
    "nlp = stanza.Pipeline(**config) # Initialize the pipeline using a configuration dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97175b36-7d95-443f-9a9b-864ef60adf48",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc489881-a0a8-4cc3-adc2-3a740689abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = nlp(\"古往今來，能飾演古龍小說人物楚留香的，無一不是娛樂圈公認的美男子，2011年，36歲的張智堯在，楚留香新傳，裡飾演楚留香，依舊帥得讓人無法自拔\")\n",
    "# print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7233087-66f1-4d4a-bec8-f062a5991623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1 word: 卡斯楚 head id: 7 head: 宣布 deprel: nsubj\n",
      "id: 2 word: 領導 head id: 7 head: 宣布 deprel: advcl\n",
      "id: 3 word: 古巴 head id: 4 head: 革命 deprel: nmod\n",
      "id: 4 word: 革命 head id: 2 head: 領導 deprel: obj\n",
      "id: 5 word: ， head id: 7 head: 宣布 deprel: punct\n",
      "id: 6 word: 並 head id: 7 head: 宣布 deprel: mark\n",
      "id: 7 word: 宣布 head id: 0 head: root deprel: root\n",
      "id: 8 word: 成 head id: 7 head: 宣布 deprel: xcomp\n",
      "id: 9 word: 為 head id: 8 head: 成 deprel: mark\n",
      "id: 10 word: 社會 head id: 12 head: 國家 deprel: nmod\n",
      "id: 11 word: 主義 head id: 12 head: 國家 deprel: nmod\n",
      "id: 12 word: 國家 head id: 8 head: 成 deprel: obj\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"卡斯楚領導古巴革命，並宣布成為社會主義國家\")\n",
    "        \n",
    "        \n",
    "for sent in doc.sentences:\n",
    "    for word in sent.words:\n",
    "        print(f\"id: {word.id}\", f\"word: {word.text}\", f\"head id: {word.head}\", \n",
    "              f\"head: {sent.words[word.head-1].text if word.head > 0 else 'root'}\", f\"deprel: {word.deprel}\")\n",
    "\n",
    "\n",
    "# # append data for graph searching\n",
    "# edges_list.append(str(token))\n",
    "# dependencies_list.append(token.dep_)\n",
    "\n",
    "    \n",
    "# print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c005aab5-9d99-4b26-85de-2ebfb5569eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['卡斯楚', '領導', '古巴', '革命', '，', '並', '宣布', '成', '為', '社會', '主義', '國家']\n",
      "['PROPN', 'VERB', 'PROPN', 'NOUN', 'PUNCT', 'ADV', 'VERB', 'VERB', 'VERB', 'NOUN', 'NOUN', 'NOUN']\n",
      "word: 卡斯楚\tupos: PROPN\txpos: NNP\tfeats: _\n",
      "word: 領導\tupos: VERB\txpos: VV\tfeats: _\n",
      "word: 古巴\tupos: PROPN\txpos: NNP\tfeats: _\n",
      "word: 革命\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: ，\tupos: PUNCT\txpos: ,\tfeats: _\n",
      "word: 並\tupos: ADV\txpos: RB\tfeats: _\n",
      "word: 宣布\tupos: VERB\txpos: VV\tfeats: _\n",
      "word: 成\tupos: VERB\txpos: VV\tfeats: _\n",
      "word: 為\tupos: VERB\txpos: VC\tfeats: _\n",
      "word: 社會\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 主義\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 國家\tupos: NOUN\txpos: NN\tfeats: _\n"
     ]
    }
   ],
   "source": [
    "# doc = nlp(\"埃及托勒密王朝在亞歷山大城建成規模巨大的亞歷山大圖書館，古希臘埃拉托色尼首創，地理學，一詞\")\n",
    "doc = nlp(\"卡斯楚領導古巴革命，並宣布成為社會主義國家\")\n",
    "\n",
    "text = []\n",
    "upos = []\n",
    "\n",
    "for sent in doc.sentences:\n",
    "    for word in sent.words:\n",
    "        text.append(word.text)\n",
    "        upos.append(word.upos)\n",
    "    \n",
    "print(text)\n",
    "print(upos)\n",
    "\n",
    "print(*[f'word: {word.text}\\tupos: {word.upos}\\txpos: {word.xpos}\\tfeats: {word.feats if word.feats else \"_\"}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d047ce8a-ea59-4aba-b562-b55329707cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'ok', 'ret': ['食用']}\n",
      "dict_keys(['status', 'ret'])\n",
      "True\n",
      "['食用']\n"
     ]
    }
   ],
   "source": [
    "from zhconv import convert\n",
    "import requests\n",
    "\n",
    "query_word = \"食用\"\n",
    "\n",
    "query_word_simplified = convert(query_word, 'zh-hans')\n",
    "\n",
    "r = requests.get(\"http://shuyantech.com/api/cnprobase/ment2ent?q=\" + query_word_simplified, verify=False)\n",
    "\n",
    "result_json = r.json()\n",
    "\n",
    "print(result_json )\n",
    "print(result_json.keys())\n",
    "print(result_json[\"status\"] == \"ok\")\n",
    "print(result_json[\"ret\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
